{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tULVmLe90Gem"
   },
   "source": [
    "# Job Title Prediction using Natural Language Processing\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This project builds an end-to-end NLP pipeline to classify job titles based on job description text.  \n",
    "The task is formulated as a supervised multi-class classification problem.\n",
    "\n",
    "A systematic modeling approach was followed:\n",
    "\n",
    "- Classical NLP baselines (TF-IDF + Naive Bayes / Logistic Regression)\n",
    "- Word Embedding-based modeling (Word2Vec)\n",
    "- Deep Learning sequence modeling (LSTM)\n",
    "- Transformer-based contextual modeling (BERT)\n",
    "\n",
    "The objective is to compare how different modeling strategies perform on structured recruitment text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXzRGmcl0MQq"
   },
   "source": [
    "## Problem Definition\n",
    "\n",
    "Given a job description, the goal is to predict the corresponding job title.\n",
    "\n",
    "This is a supervised multi-class classification problem:\n",
    "\n",
    "- **Input (X):** Job description (unstructured text)\n",
    "- **Output (y):** Job title (categorical label)\n",
    "\n",
    "Performance is evaluated on unseen test data to estimate generalization capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SQgScWpVjS3B",
    "outputId": "f9d08ba7-2113-42f6-82cf-c2f4720515ea"
   },
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXeR2ZGw81aD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywL7KbC50x1o"
   },
   "source": [
    "## NLP Resource Initialization\n",
    "\n",
    "To support preprocessing, essential NLP resources were downloaded:\n",
    "\n",
    "- `punkt` and `punkt_tab` for tokenization\n",
    "- `stopwords` corpus for filtering non-informative words\n",
    "- `wordnet` for lemmatization\n",
    "\n",
    "These resources enable standardized text cleaning and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIVqYffoF53S",
    "outputId": "d58dad75-03de-4d01-bfbd-bd44c4b20567"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2eMVnCVGF6e"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSMFn0NY0QdZ"
   },
   "source": [
    "## Data Understanding\n",
    "\n",
    "The dataset contains:\n",
    "\n",
    "- **Job Description:** Detailed text outlining responsibilities and requirements\n",
    "- **Job Title:** Categorized role (e.g., Java Developer, Data Scientist, Backend Developer)\n",
    "\n",
    "The class distribution was observed to be relatively balanced across major job roles, making it suitable for multi-class classification modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dB3_X-TB-P3v"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/content/job_title_des.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "k412Zk3D-XnI",
    "outputId": "a56a73a7-6f1b-423f-a7c1-71840b4f711f"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q14d_QRF-b4S"
   },
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAk5l4ES-uuU",
    "outputId": "347b609b-fd44-47f4-9b3e-8ba188133c22"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "R2Pu9WbkGTPP",
    "outputId": "165db21e-f3fb-4a73-9ea2-1edbacb1a8e5"
   },
   "outputs": [],
   "source": [
    "df['Job Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "K_6Zq3J5-v5g",
    "outputId": "70b58430-eaef-4672-de24-a68aa2f85247"
   },
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "mV8YM5xA-x1U",
    "outputId": "49a371ce-ed27-41d8-e96c-7081d0f14e84"
   },
   "outputs": [],
   "source": [
    "df['Job Title'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG6zNm6C1oKu"
   },
   "source": [
    "## Job Title Distribution\n",
    "\n",
    "To understand the dataset better, the frequency of each job title was visualized using a bar chart.\n",
    "\n",
    "The distribution shows that all job roles have similar sample counts, indicating a relatively balanced dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "CElqrjSA_1rd",
    "outputId": "23c858bb-3649-4da3-fe29-96196e4de48c"
   },
   "outputs": [],
   "source": [
    "df['Job Title'].value_counts().sort_values(ascending=False).plot(kind='bar')\n",
    "\n",
    "plt.title('Distribution of Job Titles', fontsize=14)\n",
    "plt.xlabel('Job Title', fontsize=12)\n",
    "plt.ylabel('Number of Samples', fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=75)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFhCxoR8ABu5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['Job Title_encoded']=le.fit_transform(df['Job Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "ZU6KljxrBZ0c",
    "outputId": "121f4d60-d41b-444f-a1c0-f85587761669"
   },
   "outputs": [],
   "source": [
    "df[['Job Title','Job Title_encoded']].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MT7ickAx4Rsn"
   },
   "source": [
    "## Text Cleaning and Lemmatization\n",
    "\n",
    "Before modeling, job descriptions were preprocessed to improve text quality and reduce noise.\n",
    "\n",
    "Steps applied:\n",
    "\n",
    "- Convert text to lowercase\n",
    "- Remove special characters and punctuation\n",
    "- Tokenize text into words\n",
    "- Remove stopwords\n",
    "- Apply lemmatization to normalize word forms\n",
    "\n",
    "Lemmatization reduces variations like \"developing\" and \"developed\" to a common base form, improving model consistency.\n",
    "\n",
    "A new feature column, **\"Job Description Lemmatized\"**, was created for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaIH8wJYB4fC"
   },
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "def clean(text):\n",
    "  text=text.lower()\n",
    "  text=re.sub(r'[^a-z\\s]','',text)\n",
    "  tokens=word_tokenize(text)\n",
    "  words=[words for words in tokens if words not in stop_words]\n",
    "  return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24k5xysyD49c"
   },
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()\n",
    "def lemmatized_word(text):\n",
    "  token=clean(text)\n",
    "  word=[lemmatizer.lemmatize(word) for word in token]\n",
    "  return ' '.join(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52KdNHsGCv7y"
   },
   "outputs": [],
   "source": [
    "df['Job Description Lemmatized']=df['Job Description'].apply(lemmatized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "kvltawRH58Iq",
    "outputId": "eb22651a-226e-41fc-d028-42b3c72f7174"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifxgPI6Q5bnY"
   },
   "source": [
    "## Feature Selection and Train-Test Split\n",
    "\n",
    "After preprocessing, the modeling dataset contains:\n",
    "\n",
    "- `Job Title_encoded` (Target variable)\n",
    "- `Job Description Lemmatized` (Processed text feature)\n",
    "\n",
    "The dataset was split into:\n",
    "\n",
    "- 70% Training data\n",
    "- 30% Test data\n",
    "\n",
    "Stratified sampling was used to maintain class distribution.\n",
    "\n",
    "The vectorizers were fit only on training data to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0G3uhg8IkzI"
   },
   "outputs": [],
   "source": [
    "df_lemmatize=df[['Job Title_encoded','Job Description Lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "_gobMoL3Ixgh",
    "outputId": "8076c6b9-5f79-4210-e541-2f6d723cac35"
   },
   "outputs": [],
   "source": [
    "df_lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8bIRleqLpzL"
   },
   "outputs": [],
   "source": [
    "x_lemm=df_lemmatize['Job Description Lemmatized']\n",
    "y_lemm=df_lemmatize['Job Title_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEZChTZwLkwA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_lemm,x_test_lemm,y_train_lemm,y_test_lemm=train_test_split(x_lemm,y_lemm,test_size=0.3,random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhJod5uC5iCl"
   },
   "source": [
    "## TF-IDF Feature Extraction\n",
    "\n",
    "TF-IDF (Term Frequency–Inverse Document Frequency) transforms text into numerical feature vectors.\n",
    "\n",
    "It:\n",
    "\n",
    "- Converts textual data into numerical representation\n",
    "- Assigns higher weight to informative terms\n",
    "- Reduces the influence of very common words\n",
    "\n",
    "This serves as the baseline feature representation for classical ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4_k1aQhJEhC"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(lowercase=True,stop_words='english',max_features=5000)\n",
    "x_train_vectorized_lemmatized=tfidf.fit_transform(x_train_lemm)\n",
    "x_test_vectorized_lemmatized=tfidf.transform(x_test_lemm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGuYYLr658Cq"
   },
   "source": [
    "## Multinomial Naive Bayes (TF-IDF on Lemmatized Text)\n",
    "\n",
    "A Multinomial Naive Bayes classifier was trained using TF-IDF features generated from lemmatized text.\n",
    "\n",
    "Naive Bayes is commonly used in text classification because:\n",
    "\n",
    "- It performs well with high-dimensional sparse data\n",
    "- It is computationally efficient\n",
    "- It provides a strong baseline for NLP tasks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "AbBE5fzhMH5d",
    "outputId": "56368d37-f8ec-43a1-a98b-9be895a42b8e"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nm_lemmatized_model=MultinomialNB()\n",
    "nm_lemmatized_model.fit(x_train_vectorized_lemmatized,y_train_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9SM3iJe1ZqT"
   },
   "outputs": [],
   "source": [
    "y_pred_lemmatized=nm_lemmatized_model.predict(x_test_vectorized_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eo66ZOu16BNI"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "The model was evaluated using:\n",
    "\n",
    "- Accuracy\n",
    "- Precision (Weighted)\n",
    "- Recall (Weighted)\n",
    "- F1-Score\n",
    "- Confusion Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0ri77Sk0mry",
    "outputId": "c96228c9-b9ee-44f7-fd8b-467d6b1c72c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,classification_report,precision_recall_fscore_support\n",
    "print('accuracy score for a multinomial model built on lemmatized text is',accuracy_score(y_test_lemm,y_pred_lemmatized))\n",
    "print('\\n')\n",
    "print('precision score for a multinomial model built on lemmatized text is',precision_score(y_test_lemm,y_pred_lemmatized, average='weighted'))\n",
    "print('\\n')\n",
    "print('recall score for a multinomial model built on lemmatized text is',recall_score(y_test_lemm,y_pred_lemmatized, average='weighted'))\n",
    "print('\\n')\n",
    "print('classification report for a multinomial model built on lemmatized text is','\\n',classification_report(y_test_lemm,y_pred_lemmatized))\n",
    "print('\\n')\n",
    "print('confusion matrix for a multinomial model built on lemmatized text is','\\n',confusion_matrix(y_test_lemm,y_pred_lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6TDDFUfdEHM"
   },
   "source": [
    "### Observations\n",
    "\n",
    "- The model achieved an accuracy of approximately **66%** on the test dataset.\n",
    "- Precision and recall scores indicate moderate performance across job title categories.\n",
    "- Some classes perform better than others, suggesting opportunities for improvement using more advanced models.\n",
    "\n",
    "This baseline establishes a performance benchmark before experimenting with more complex architectures such as LSTM or Transformer-based models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pztKoYtZpPTv"
   },
   "source": [
    "## TF-IDF Feature Extraction\n",
    "\n",
    "TF-IDF (Term Frequency–Inverse Document Frequency) was used to convert raw job descriptions into numerical feature vectors.\n",
    "\n",
    "TF-IDF:\n",
    "\n",
    "- Measures the importance of a word within a document relative to the entire corpus  \n",
    "- Reduces the influence of very common words  \n",
    "- Preserves discriminative keywords useful for classification  \n",
    "\n",
    "The vectorizer was fitted on the training data to avoid data leakage, and the same transformation was applied to the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n91KFyIBP0C1"
   },
   "outputs": [],
   "source": [
    "x=df['Job Description']\n",
    "y=df['Job Title_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1jizyXbQRVp"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN8SKT7lPh7X"
   },
   "outputs": [],
   "source": [
    "x_train_vectorized=tfidf.fit_transform(x_train)\n",
    "x_test_vectorized=tfidf.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_hjGWloliPW"
   },
   "source": [
    "## Multinomial Naive Bayes (TF-IDF on Raw Text)\n",
    "\n",
    "TF-IDF features were generated directly from raw job descriptions.\n",
    "\n",
    "The goal was to compare performance between:\n",
    "\n",
    "- Raw text representation\n",
    "- Lemmatized text representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Qhfti0AQZ7A"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhUt521MQeLO"
   },
   "outputs": [],
   "source": [
    "nm_model=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "IsfPBPNnQkKh",
    "outputId": "097c8a48-d712-4a16-cb2c-d77f67faceb7"
   },
   "outputs": [],
   "source": [
    "nm_model.fit(x_train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XhKs6ApQm3e"
   },
   "outputs": [],
   "source": [
    "y_pred_nb=nm_model.predict(x_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLiGUzxO2_-F",
    "outputId": "3ac8596b-69c4-4684-94f0-5c9ec9fca080"
   },
   "outputs": [],
   "source": [
    "print('accuracy score for a multinomial model is',accuracy_score(y_test,y_pred_nb))\n",
    "print('\\n')\n",
    "print('precision score for a multinomial model is',precision_score(y_test,y_pred_nb, average='weighted'))\n",
    "print('\\n')\n",
    "print('recall score for a multinomial model is',recall_score(y_test,y_pred_nb, average='weighted'))\n",
    "print('\\n')\n",
    "print('classification report for a multinomial model is','\\n',classification_report(y_test,y_pred_nb))\n",
    "print('\\n')\n",
    "print('confusion matrix for a multinomial model is','\\n',confusion_matrix(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KP5cHvmEdAEm"
   },
   "source": [
    "### Results\n",
    "\n",
    "The model achieved approximately **75% accuracy**, outperforming the lemmatized version.\n",
    "\n",
    "This suggests that TF-IDF on raw text preserved sufficient discriminative information for this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJ4duKTzDy-r"
   },
   "source": [
    "## Logistic Regression (TF-IDF on Raw Text)\n",
    "\n",
    "TF-IDF features were generated directly from the raw job descriptions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Fz6A94e43ZU"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKznp2qIElj3"
   },
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "DMJgzAW1Em52",
    "outputId": "dca4a5d1-1d12-442a-cbf2-e5c24564ec9e"
   },
   "outputs": [],
   "source": [
    "lr.fit(x_train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9iGyNi88EsaH"
   },
   "outputs": [],
   "source": [
    "y_pred_lr=lr.predict(x_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vnuLicDHfnQ",
    "outputId": "67ecec59-0c53-4d2e-e3aa-a3a7133125ef"
   },
   "outputs": [],
   "source": [
    "print('accuracy score for a Logistic Model is',accuracy_score(y_test,y_pred_lr))\n",
    "print('\\n')\n",
    "print('precision score for a Logistic Model is',precision_score(y_test,y_pred_lr, average='weighted'))\n",
    "print('\\n')\n",
    "print('recall score for a Logistic Model  is',recall_score(y_test,y_pred_lr, average='weighted'))\n",
    "print('\\n')\n",
    "print('classification report for a Logistic Model is','\\n',classification_report(y_test,y_pred_lr))\n",
    "print('\\n')\n",
    "print('confusion matrix for a Logistic Model is','\\n',confusion_matrix(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l999V35IdM9o"
   },
   "source": [
    "\n",
    "### Results\n",
    "\n",
    "The model achieved approximately **82–83% accuracy**, outperforming Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g33-QpA_gHzt"
   },
   "source": [
    "## Word2Vec + Logistic Regression (Raw Text)\n",
    "\n",
    "Word2Vec was trained directly on the raw job descriptions to learn dense word embeddings based on contextual relationships.\n",
    "\n",
    "Each job description was converted into a fixed-length vector by averaging the embeddings of its words. These vectors were then used as input features for a Logistic Regression classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ni95Hu2jf7EZ"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmw9Xr-3jumh"
   },
   "outputs": [],
   "source": [
    "sentences = [sent.split() for sent in df['Job Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Ag_ogjsjMkK"
   },
   "outputs": [],
   "source": [
    "word2vec_model=Word2Vec(sentences=sentences,vector_size=1000,window=1,sg=0,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFJDXY7V36p6"
   },
   "outputs": [],
   "source": [
    "def sentences2vec_wv(inp_sentences,vec_model):\n",
    "  vectors=[vec_model.wv[word] for word in inp_sentences if word in vec_model.wv]\n",
    "  if not vectors:\n",
    "    return np.zeros(vec_model.vector_size)\n",
    "  return np.mean(vectors,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zzV6C-l397B"
   },
   "outputs": [],
   "source": [
    "x_vector_wv=[sentences2vec_wv(sent.split(),word2vec_model) for sent in df['Job Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNpfiItA3_Qu"
   },
   "outputs": [],
   "source": [
    "x_train_wv,x_test_wv,y_train_wv,y_test_wv=train_test_split(x_vector_wv,y,test_size=0.3,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bui_b3ul2_Zx"
   },
   "outputs": [],
   "source": [
    "lr_word2vec_pre_trained=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "vPP3WQa-3uAk",
    "outputId": "4b94e7ce-9401-4f01-cd11-0ca6f2bf3a40"
   },
   "outputs": [],
   "source": [
    "lr_word2vec_pre_trained.fit(x_train_wv,y_train_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Qu9Mqco4IM_"
   },
   "outputs": [],
   "source": [
    "y_pred_wv=lr_word2vec_pre_trained.predict(x_test_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQunoKmT4Ssf",
    "outputId": "b06570f4-f28f-4864-cc78-75bf99d1c78f"
   },
   "outputs": [],
   "source": [
    "print('accuracy score for a Logistic Model for Word2Vec Model is',accuracy_score(y_test_wv,y_pred_wv))\n",
    "print('\\n')\n",
    "print('precision score for a Logistic Model for Word2Vec Model is',precision_score(y_test_wv,y_pred_wv, average='weighted'))\n",
    "print('\\n')\n",
    "print('recall score for a Logistic Model for Word2Vec Model is',recall_score(y_test_wv,y_pred_wv, average='weighted'))\n",
    "print('\\n')\n",
    "print('classification report for a Logistic Model for Word2Vec Model is','\\n',classification_report(y_test_wv,y_pred_wv))\n",
    "print('\\n')\n",
    "print('confusion matrix for a Logistic Model for Word2Vec Model is','\\n',confusion_matrix(y_test_wv,y_pred_wv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0CdFXPTg-Ht"
   },
   "source": [
    "### Result\n",
    "\n",
    "The model achieved significantly lower performance compared to TF-IDF-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjPOX6IARZBP"
   },
   "source": [
    "## LSTM-Based Text Classification\n",
    "\n",
    "A deep learning model was built using an Embedding layer followed by an LSTM network.\n",
    "\n",
    "The tokenizer converted job descriptions into numerical sequences, which were padded to a fixed length before training.\n",
    "\n",
    "The model architecture consists of:\n",
    "- Embedding layer for dense word representations\n",
    "- LSTM layer to capture sequential dependencies\n",
    "- Dropout layer for regularization\n",
    "- Dense output layer with softmax activation for multi-class classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7K6FDKRBlW3n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9_SfgpNmAL7",
    "outputId": "f1c78d13-b4e3-4a25-f434-bd20d4434981"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvMB9P4YnPye"
   },
   "outputs": [],
   "source": [
    "sent = df['Job Description'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoRvBM7wlhuI"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=10000,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv9wPetrmi5z"
   },
   "outputs": [],
   "source": [
    "max_len=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyzen_5cl2dv"
   },
   "outputs": [],
   "source": [
    "seq=tokenizer.texts_to_sequences(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9zY-80aemXPv"
   },
   "outputs": [],
   "source": [
    "x_padded=pad_sequences(seq,max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9C-lBU6Ymj8Q"
   },
   "outputs": [],
   "source": [
    "x_padded_train,x_padded_test,y_train,y_test=train_test_split(x_padded,y,test_size=0.3,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFsrSoIkmxyv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dropout,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHECsnyaqc6J",
    "outputId": "6a70a900-f8d1-4394-866b-0afce0f7b4b9"
   },
   "outputs": [],
   "source": [
    "lstm_model=Sequential([\n",
    "    Embedding(input_dim=10000,output_dim=128,input_length=max_len),\n",
    "    LSTM(64,return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(15,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0Aq4Cg2rAoz"
   },
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "hxnJb5DxrT69",
    "outputId": "5ef79712-7a4d-424c-ec55-04aa2d52bd5c"
   },
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8UHzx30rV5E",
    "outputId": "f5855c69-bea4-4de1-8527-b2a735f82589"
   },
   "outputs": [],
   "source": [
    "lstm_model.fit(x_padded_train,y_train,epochs=50,validation_split=0.1,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hq5XFjk7rcIw",
    "outputId": "94d98de1-28e1-4d1a-8316-0cf831ccbfe4"
   },
   "outputs": [],
   "source": [
    "y_pred_lstm=lstm_model.predict(x_padded_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ku3uU11MtZix",
    "outputId": "edb72a3f-3850-4ffc-c27e-d21fdb8ecb03"
   },
   "outputs": [],
   "source": [
    "y_pred_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwsr7zNItVGw"
   },
   "outputs": [],
   "source": [
    "y_pred_lstm_val=np.argmax(y_pred_lstm,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNIG8jmKtcbQ",
    "outputId": "3c2a3e1a-7739-45df-a0fc-fc410d64ff9e"
   },
   "outputs": [],
   "source": [
    "y_pred_lstm_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbmU2PicspNM",
    "outputId": "4ffd3416-d40c-4fa8-f575-396242eb7bad"
   },
   "outputs": [],
   "source": [
    "print('accuracy score for LSTM is',accuracy_score(y_test,y_pred_lstm_val))\n",
    "print('\\n')\n",
    "print('precision score for LSTM is',precision_score(y_test,y_pred_lstm_val, average='weighted'))\n",
    "print('\\n')\n",
    "print('recall score for LSTM is',recall_score(y_test,y_pred_lstm_val, average='weighted'))\n",
    "print('\\n')\n",
    "print('classification report for LSTM is','\\n',classification_report(y_test,y_pred_lstm_val))\n",
    "print('\\n')\n",
    "print('confusion matrix for LSTM is','\\n',confusion_matrix(y_test,y_pred_lstm_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIKcwAr6n2oO"
   },
   "source": [
    "### Result\n",
    "\n",
    "The LSTM model achieved moderate performance but did not outperform TF-IDF + Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "220Efgvjbs6a"
   },
   "source": [
    "##Transformer-Based Model\n",
    "\n",
    "Transformer models use self-attention to understand contextual meaning in text.\n",
    "They capture long-range dependencies better than traditional NLP models.\n",
    "\n",
    "In this project, a pre-trained Transformer model was fine-tuned\n",
    "for multi-class job title classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jPuwb849s7zq",
    "outputId": "4f80e32e-721a-4e80-9de7-c42a78eda35b"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NkCu5or9CZ33"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxybBOiSCgnZ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['Job Description'],\n",
    "    df['Job Title_encoded'],\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=df['Job Title_encoded']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCOjX3vXCinM"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "test_df = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "c0a139719e744850b6d3b099ffc01e23",
      "6f1af859ae594a4bbba4b885d906aa0d",
      "aa7092416be54a3d9040415023b38187",
      "01de0368ac944160bd5899110a9e1d28",
      "f096f6798dcf4098b3ea093ebd6629a3",
      "a8996b13955c475c9dfbd5d089c54214",
      "2fac5f8098214d12a405f8e9d49fb136",
      "70fdbe4b13c342b3998acebeff8e0f89",
      "5cfc0d42a86f46c991cb6be4972ab906",
      "6d3f3fb26e0a4710aaa997630601dba6",
      "e2069cd0b7d64ed6b50a9607422a448e",
      "78a30c45bc7f430382dd4abc1efcff90",
      "f60b3446988448c19fef1e9b22b58d9f",
      "60d7fd6beb8d48589a70e6667d606f77",
      "ee14d29245024efc8279c847e2de5c85",
      "7e2ae02b3eb94cae9f370265c5af8a34",
      "7d2974c4273348c39b7fe41eca457509",
      "522fb47d96df4f78be8b2789c4e3a9b6",
      "f0101c259a424452a916982740034770",
      "e36a95998e4c426b91be064f2b57ccc4",
      "ee6f0362a91143a5a782b0de563be6cd",
      "b80fd464491844ed81962e5ab8142515",
      "54517d0dc9f94ee0bca665ec331750b8",
      "6843f33ac46f49ccbb278268240895f7",
      "9cac5b63f30f4d55986d30bc4185a023",
      "1021fd887ff54385a6179d0181792ecd",
      "29ad6fbc69874db6bd4d634340a0978f",
      "ed3ceb89703846a49b7cdbd0c782e1bc",
      "0650f4169e6f405ea1bcb88e67bb39fe",
      "5092e6f1409e4eb0be5f346c29e6e58a",
      "b04b372ce88540e398c6da84644f4cee",
      "9c0cc1cd4d6842a6940d3fe3c23ae765",
      "924355ae96fc4e61902ce4a09efa807e"
     ]
    },
    "id": "GMy6ZKVbCkUt",
    "outputId": "98eb75dd-6990-4bc5-98d3-638780729894"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "4812e9a1383c4eb282115f1420c5508d",
      "3eba140856db49aebaedfaa85c74ac5a",
      "cba4b904edd844cd9e42556ea8e00226",
      "f8cf1741cf10467ba83f28c409db90b6",
      "7461af100df2456b8177e42353f67a95",
      "2fb3bb687b584370989c1aacb236375d",
      "4b82ce58d6c34140b802738899e44de4",
      "00a1566ed1e24cf8ad925d5ceffabb45",
      "c6ba7a2a8faa4d32b395218f76027026",
      "ecc26e34df254df7854fd8a240697291",
      "05092fccf4784ccabce6e47c3a94ee59",
      "8658a2494c4a4b538e5f430b81694fb8",
      "8a0dda30aff8432d8e3935ed9e774c9a",
      "a364c14453a544df844dcd2dec3b6882",
      "0c3faa38752149a39df9a851a6049488",
      "a4007fe6ccf34e64bcda102b83647761",
      "6895d25c51fd418dabb311b507913230",
      "cadce6d6683d4f8481b6a39bc3e9249a",
      "8e7a6b27982f4775a675b6273266107a",
      "f83eb0cc3c7e4a91961d25a433e164be",
      "a4f5cbb156bf4c48bc83ae537d6c3d77",
      "4cc7deaa989f432cb6ed3adbed96f09b"
     ]
    },
    "id": "D1vp3xvoCoFQ",
    "outputId": "c825e198-ab49-4949-bee4-89baeec08dbe"
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391,
     "referenced_widgets": [
      "c0606bfae5254128916ceba3e4d70d4e",
      "de9d81dd5eec48f690928efa64506858",
      "d9764d4db8804ef6a1c1acdd56052a07",
      "6b57c643a792444db39b36ee6961aafe",
      "c0598f8f8c9643238444b0d9edc6a7d0",
      "302d5b10d83542debe54969158efec24",
      "19f6c4edaf66497b959f04f965320e67",
      "6e4690a6367542419a30772768ab4e7d",
      "24dbcf627db9465281669196cbe9dbfc",
      "7540a0c743e94c29be4405bfed60102e",
      "bc9c284af2414305a20f39d19037c51a",
      "d5774ee169144cd2ab76175632ecd44b",
      "d623234aa83e47be9821d8e3648c325b",
      "448eab095fb84d6a88129bc184d76026",
      "4c63d5871bd240ba9e1508050c29556a",
      "2418d6b4979944d1a0e4d8bcf5867ac4",
      "ee13072cd8e945a8afeb4bd4c88bc3ba",
      "11036675a18548469ec295f569199a10",
      "ca1bbb70539640c7bdba91e87685ecf4",
      "50085922b5864252853035b422e92eb6",
      "97464ada04ba46b7a6f4853949e03d35",
      "bd31b34eecd94a29bb1c12b358abdbef",
      "5f0a95d9c20b4947ab349449348454f3",
      "74a0b0b7831a4865aaa4392bad615bcd",
      "c048a4f255c04ebca5afb70dd2a7467f",
      "bf37903158f548f5bc263dc6c3492b30",
      "f6bf41c81ed8463eb77625c42411978a",
      "a005e865dd9d4dc688e606d56fa9b8d1",
      "bd4246a65d584685827273fc5d5a39cb",
      "18c24c4486e24223a1906a75d38ea62d",
      "f9fe950eea90435d860f2684cc68cba1",
      "6012120883ca4629a8c77f3fb196c938",
      "77bfac362a644bb0983d7cf964835c5e"
     ]
    },
    "id": "wyO-RyMHCqbS",
    "outputId": "6ac6f9e4-e533-4cfe-b647-c45827342324"
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T56NTlYECsp4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted'\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jvFfySob8h6"
   },
   "source": [
    "##BERT (bert-base-uncased)\n",
    "\n",
    "BERT is a bidirectional Transformer model pre-trained on large corpora.\n",
    "It understands context from both left and right directions.\n",
    "\n",
    "Configuration:\n",
    "- Model: bert-base-uncased\n",
    "- Max Length: 128\n",
    "- Epochs: 2\n",
    "- Batch Size: 8\n",
    "- Learning Rate: 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cWOijGgwCu1C",
    "outputId": "2308405b-674f-4058-8404-bd338df6f351"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEOPqZesCwxn"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291,
     "referenced_widgets": [
      "6efc0cdd08e749a1a98860ddf0dfb58b",
      "59a45a93547e4bf586bac6ed06f4a186",
      "fa7ac7f86f2d40a5bd56143a225445f2",
      "fdabff8d018a44fd93c0bc0271e7da17",
      "73439954b74f4809b9fbc2d871e3186f",
      "466f8f5d18f24ab8a69a9db82600690b",
      "6eee4d1bdf07406ab42d5311caf42cfe",
      "3f7124c0d2824ddfbc46ab49e80f483e",
      "889a835e0d50490fa435ff5f12eacf98",
      "49d1cb01a5cd4f2485bd18f85076bffb",
      "f29bb167c696422fb829fe88decc249b",
      "bd44d88e855e4d7a9af9f04f5ebf4a5b",
      "4875361f35e74d00aa769a22ea4a063b",
      "011e1c93b8f7470db9b49bea3e37a554",
      "7d447068bf9846a5bd5101adefae5b98",
      "524105ed2a6a4654aa301b8653ceaf0e",
      "fdea922c52774b89918b8f29fb72fc95",
      "b93b5579b7aa4b8985d049efba699831",
      "e95469ffab834d7b9da8f2fac6d36b28",
      "fbc681083baa4b6da7f083ec12c2fc08",
      "7eab16612d0c4da78feb13991a714c1d",
      "11e0876e804340e891504eac22a730df"
     ]
    },
    "id": "vwhYE1nRCyY5",
    "outputId": "8578303f-b9c6-4bda-8098-96c49d09632b"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "m4mJv51ZCzjT",
    "outputId": "8ca5e177-ebbe-4c89-c0c5-21c5a1cbc0e9"
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-Ja_30EcDB3"
   },
   "source": [
    "##Results\n",
    "\n",
    "The fine-tuned BERT model achieved:\n",
    "\n",
    "- Accuracy: ~79%\n",
    "- Weighted F1-score: ~0.79\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eWR5GJ-7cVMA"
   },
   "source": [
    "##Final Conclusion\n",
    "\n",
    "This project compared multiple NLP approaches for multi-class job title prediction, including TF-IDF, Word2Vec, LSTM, and BERT.\n",
    "\n",
    "Among all models, **TF-IDF + Logistic Regression achieved the highest accuracy (~83%)**, indicating that the dataset is strongly driven by keyword-level patterns.\n",
    "\n",
    "While advanced models like LSTM and BERT provided contextual understanding, classical linear modeling generalized better due to the dataset size and problem structure.\n",
    "\n",
    "This demonstrates that effective model selection depends on data characteristics, and higher model complexity does not always guarantee better performance."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
